{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"https://github.com/OpenMined/design-assets/raw/master/logos/OM/mark-primary-trans.png\" align=\"center\" style=\"width: 100px;\"/> TenSEAL Demo\n",
    "\n",
    "Welcome to this tutorial, where we will show the core functionality of TenSEAL and some use cases.\n",
    "\n",
    "If you find it interesting, check out the other tutorials as well:\n",
    "- ['Tutorial 0 - Getting Started'](./Tutorial%200%20-%20Getting%20Started.ipynb).\n",
    "- ['Tutorial 1: Training and Evaluation of Logistic Regression on Encrypted Data'](./tutorials/Tutorial%201%20-%20Training%20and%20Evaluation%20of%20Logistic%20Regression%20on%20Encrypted%20Data.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "All modules are imported here. Make sure everything is installed by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from random import randint\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "from typing import Dict\n",
    "\n",
    "import tenseal as ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TenSEAL Context\n",
    "\n",
    "TenSEAL context is the central component of the library.  It stores the keys and states required by an encrypted computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context():\n",
    "    context = ts.context(ts.SCHEME_TYPE.CKKS, 8192, coeff_mod_bit_sizes=[60, 40, 40, 60])\n",
    "    context.global_scale = pow(2, 40)\n",
    "    context.generate_galois_keys()\n",
    "    return context\n",
    "\n",
    "context = context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plain tensor creation\n",
    "\n",
    "PlainTensor class works as a translation layer from common tensor representations to the encrypted forms offered by TenSEAL.\n",
    "\n",
    "<img src=\"assets/plaintensor_indepth.png\" align=\"center\" style=\"display: block;  margin: auto;\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " First tensor: Shape = [2, 2] Data = [[1.0, 2.0], [3.0, 4.0]]\n",
      " Second tensor: Shape = [2, 2] Data = [[5.0, 6.0], [7.0, 8.0]]\n"
     ]
    }
   ],
   "source": [
    "plain1 = ts.plain_tensor([1,2,3,4], [2,2])\n",
    "plain1_list = ts.tolist(plain1)\n",
    "print(\" First tensor: Shape = {} Data = {}\".format(plain1.shape(), plain1_list))\n",
    "\n",
    "plain2 = ts.plain_tensor(np.array([5,6,7,8]).reshape(2,2))\n",
    "plain2_list = ts.tolist(plain2)\n",
    "print(\" Second tensor: Shape = {} Data = {}\".format(plain2.shape(), plain2_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encrypted tensor creation\n",
    "\n",
    "The encrypted tensor encrypts a PlainTensor and stores the ciphertexts and shapes internally.\n",
    "\n",
    "We have a few variants of encrypted tensors:\n",
    " - **BFVVector** - for 1d integer arrays.\n",
    " - **CKKSVector** - for 1d float arrays.\n",
    " - **CKKSTensor** - for n-dimensional float arrays.\n",
    " \n",
    " \n",
    "<img src=\"assets/encrypted_tensor_relation.png\" align=\"center\" style=\"display: block;  margin: auto;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape = [2, 2]\n",
      " Encrypted Data = [<_tenseal_cpp.Ciphertext object at 0x7f82826647b0>, <_tenseal_cpp.Ciphertext object at 0x7f82826645b0>, <_tenseal_cpp.Ciphertext object at 0x7f8282664730>, <_tenseal_cpp.Ciphertext object at 0x7f8282664870>].\n"
     ]
    }
   ],
   "source": [
    "encrypted_tensor1 = ts.ckks_tensor(context, plain1)\n",
    "encrypted_tensor2 = ts.ckks_tensor(context, plain2)\n",
    "\n",
    "print(\" Shape = {}\".format(encrypted_tensor1.shape()))\n",
    "print(\" Encrypted Data = {}.\".format(encrypted_tensor1.data()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrypt(enc):\n",
    "    return ts.tolist(enc.decrypt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain equivalent: [[1.0, 2.0], [3.0, 4.0]] + [[5.0, 6.0], [7.0, 8.0]]\n",
      "Decrypted result: [[5.999999999815346, 7.999999998751939], [9.999999999667072, 12.00000000226877]].\n"
     ]
    }
   ],
   "source": [
    "result = encrypted_tensor1 + encrypted_tensor2\n",
    "print(\"Plain equivalent: {} + {}\\nDecrypted result: {}.\".format(plain1_list, plain2_list, decrypt(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain equivalent: [[1.0, 2.0], [3.0, 4.0]] - [[5.0, 6.0], [7.0, 8.0]]\n",
      "\n",
      "Decrypted result: [[-3.999999999636935, -3.9999999976117824], [-4.000000001227462, -4.000000001552208]].\n"
     ]
    }
   ],
   "source": [
    "result = encrypted_tensor1 - encrypted_tensor2\n",
    "print(\"Plain equivalent: {} - {}\\nDecrypted result: {}.\".format(plain1_list, plain2_list, decrypt(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain equivalent: [[1.0, 2.0], [3.0, 4.0]] * [[5.0, 6.0], [7.0, 8.0]]\n",
      "Decrypted result: [[5.000000670032934, 12.000001607714392], [21.00000281341945, 32.0000043009525]].\n"
     ]
    }
   ],
   "source": [
    "result = encrypted_tensor1 * encrypted_tensor2\n",
    "print(\"Plain equivalent: {} * {}\\nDecrypted result: {}.\".format(plain1_list, plain2_list, decrypt(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplication with plain tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain equivalent: [[1.0, 2.0], [3.0, 4.0]] * [[5.0, 6.0], [7.0, 8.0]]\n",
      "Decrypted result: [[5.000000672842045, 12.000001612945578], [21.00000281166497, 32.00000429575837]].\n"
     ]
    }
   ],
   "source": [
    "plain = ts.plain_tensor([5,6,7,8], [2,2])\n",
    "result = encrypted_tensor1 * plain\n",
    "\n",
    "print(\"Plain equivalent: {} * {}\\nDecrypted result: {}.\".format(plain1_list, ts.tolist(plain), decrypt(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain equivalent: [[1.0, 2.0], [3.0, 4.0]] ^ 3\n",
      "Decrypted result: [[1.000000808179847, 8.000006449083985], [27.00002170307704, 64.00005151254288]].\n"
     ]
    }
   ],
   "source": [
    "result = encrypted_tensor1 ** 3\n",
    "print(\"Plain equivalent: {} ^ 3\\nDecrypted result: {}.\".format(plain1_list, decrypt(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial evaluation $1 + X^2 + X^3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [[1.0, 2.0], [3.0, 4.0]]\n",
      "1 + X^2 + X^3 = [[3.000000943001977, 13.000006988374018], [37.0000229046437, 81.00005366152166]].\n"
     ]
    }
   ],
   "source": [
    "result = encrypted_tensor1.polyval([1,0,1,1])\n",
    "\n",
    "print(\"X = {}\".format(plain1_list))\n",
    "print(\"1 + X^2 + X^3 = {}.\".format(decrypt(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid approximation\n",
    "$\\sigma(x) = 0.5 + 0.197 x - 0.004 x^3$\n",
    "\n",
    "Reference: [\"Logistic regression over encrypted data from fully homomorphic encryption\", Hao Chen et al](https://eprint.iacr.org/2018/462.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [[1.0, 2.0], [3.0, 4.0]]\n",
      "0.5 + 0.197 X - 0.004 x^X = [[0.693000019597699, 0.8620000166913684], [0.9829999803609126, 1.0319998768348877]].\n"
     ]
    }
   ],
   "source": [
    "result = encrypted_tensor1.polyval([0.5, 0.197, 0, -0.004])\n",
    "\n",
    "\n",
    "print(\"X = {}\".format(plain1_list))\n",
    "print(\"0.5 + 0.197 X - 0.004 x^X = {}.\".format(decrypt(result)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encrypted inference demo\n",
    "\n",
    "The next example contains a classification over the MNIST dataset using a single convolution and two fully connected layers with a square activation function.\n",
    "\n",
    "It illustrates one of the prominent use cases for homomorphic encryption, as depicted here.\n",
    "\n",
    "<img src=\"https://blog.openmined.org/content/images/2020/04/OM---CKKS-Graphic-v.01@2x.png\" align=\"center\" style=\"display: block;  margin: auto;\"/>\n",
    "\n",
    "\n",
    "Adapted from https://github.com/youben11/encrypted-evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TenSEAL security context\n",
    "def create_ctx():\n",
    "    poly_mod_degree = 8192\n",
    "    coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
    "    ctx = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "    ctx.global_scale = 2 ** 21\n",
    "    ctx.generate_galois_keys()\n",
    "    return ctx\n",
    "\n",
    "# Sample an image\n",
    "def load_input():\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    )\n",
    "    idx = randint(1, 39)\n",
    "    img_name = \"samples/img_{}.jpg\".format(idx)\n",
    "    img = Image.open(img_name)\n",
    "    return transform(img).view(28, 28).tolist(), img\n",
    "\n",
    "# Encode the image\n",
    "def prepare_input(ctx, plain_input):\n",
    "    enc_input, windows_nb = ts.im2col_encoding(ctx, plain_input, 7, 7, 3)\n",
    "    assert windows_nb == 64\n",
    "    return enc_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server Model\n",
    "\n",
    " - We have a pretrained plain model.\n",
    " - We adapt the forward call for encrypted inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model and adapt the forward call for encrypted input\n",
    "class ConvMNIST():\n",
    "    \"\"\"CNN for classifying MNIST data.\n",
    "    Input should be an encoded 28x28 matrix representing the image.\n",
    "    TenSEAL can be used for encoding `tenseal.im2col_encoding(ctx, input_matrix, 7, 7, 3)`\n",
    "    The input should also be normalized with a mean=0.1307 and an std=0.3081 before encryption.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, parameters: Dict[str, list]):\n",
    "        self.conv1_weight = parameters[\"conv1_weight\"]\n",
    "        self.conv1_bias = parameters[\"conv1_bias\"]\n",
    "        self.fc1_weight = parameters[\"fc1_weight\"]\n",
    "        self.fc1_bias = parameters[\"fc1_bias\"]\n",
    "        self.fc2_weight = parameters[\"fc2_weight\"]\n",
    "        self.fc2_bias = parameters[\"fc2_bias\"]\n",
    "        self.windows_nb = parameters[\"windows_nb\"]\n",
    "\n",
    "    def forward(self, enc_x: ts.CKKSVector) -> ts.CKKSVector:\n",
    "        # conv layer\n",
    "        channels = []\n",
    "        for kernel, bias in zip(self.conv1_weight, self.conv1_bias):\n",
    "            y = enc_x.conv2d_im2col(kernel, self.windows_nb) + bias\n",
    "            channels.append(y)\n",
    "        out = ts.CKKSVector.pack_vectors(channels)\n",
    "        # squaring\n",
    "        out.square_()\n",
    "        # no need to flat\n",
    "        # fc1 layer\n",
    "        out.mm_(self.fc1_weight).add_plain_(self.fc1_bias)\n",
    "        # squaring\n",
    "        out.square_()\n",
    "        # output layer\n",
    "        out.mm_(self.fc2_weight).add_plain_(self.fc2_bias)\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_input(context: bytes, ckks_vector: bytes) -> ts.CKKSVector:\n",
    "        try:\n",
    "            ctx = ts.context_from(context)\n",
    "            enc_x = ts.ckks_vector_from(ctx, ckks_vector)\n",
    "        except:\n",
    "            raise DeserializationError(\"cannot deserialize context or ckks_vector\")\n",
    "        try:\n",
    "            _ = ctx.galois_keys()\n",
    "        except:\n",
    "            raise InvalidContext(\"the context doesn't hold galois keys\")\n",
    "\n",
    "        return enc_x\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from 'parameters/ConvMNIST-0.1.pickle'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "def load_parameters(file_path: str) -> dict:\n",
    "    try:\n",
    "        parameters = pickle.load(open(file_path, \"rb\"))\n",
    "        print(f\"Model loaded from '{file_path}'\")\n",
    "    except OSError as ose:\n",
    "        print(\"error\", ose)\n",
    "        raise ose\n",
    "    return parameters\n",
    "\n",
    "\n",
    "\n",
    "parameters = load_parameters(\"parameters/ConvMNIST-0.1.pickle\")\n",
    "model = ConvMNIST(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Query\n",
    "\n",
    "**Steps**:\n",
    " - Context creation(only for the first query).\n",
    " - Image sampling and encryption.\n",
    " - Image and context serialization using **Protobuffers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encrypted image  <_tenseal_cpp.CKKSVector object at 0x7f8280114b70>\n",
      "Original image \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "context = create_ctx()\n",
    "image, orig = load_input()\n",
    "    \n",
    "encrypted_image = prepare_input(context, image)\n",
    "\n",
    "print(\"Encrypted image \", encrypted_image)\n",
    "print(\"Original image \")\n",
    "imshow(np.asarray(orig))\n",
    "\n",
    "server_context = context.serialize()\n",
    "encrypted_image = encrypted_image.serialize()\n",
    "\n",
    "\n",
    "\n",
    "client_query = {\n",
    "    \"data\" : encrypted_image,\n",
    "    \"context\" : server_context,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server inference\n",
    "\n",
    "**Steps**:\n",
    " - Deserialize the context and the encrypted image.\n",
    " - Run the inference.\n",
    " - Serialize and return the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encrypted_query = model.prepare_input(client_query[\"context\"], client_query[\"data\"])\n",
    "encrypted_result = model(encrypted_query).serialize()\n",
    "\n",
    "server_response = {\n",
    "    \"data\" : encrypted_result\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client process response\n",
    "\n",
    "Steps:\n",
    " - Deserialize the response.\n",
    " - Decrypt the response.\n",
    " - Apply a softmax and return the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum probability for label 5\n"
     ]
    }
   ],
   "source": [
    "result = ts.ckks_vector_from(context, server_response[\"data\"]).decrypt()\n",
    "\n",
    "probs = torch.softmax(torch.tensor(result), 0)\n",
    "label_max = torch.argmax(probs)\n",
    "print(\"Maximum probability for label {}\".format(label_max))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
