{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TenSEAL Demo\n",
    "\n",
    "Welcome to this tutorial, where we are going to show the core functionality of TenSEAL and some use cases.\n",
    "\n",
    "If you find it interesting, check out the other tutorials as well:\n",
    "- ['Tutorial 0 - Getting Started'](./Tutorial%200%20-%20Getting%20Started.ipynb).\n",
    "- ['Tutorial 1: Training and Evaluation of Logistic Regression on Encrypted Data'](./tutorials/Tutorial%201%20-%20Training%20and%20Evaluation%20of%20Logistic%20Regression%20on%20Encrypted%20Data.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "All modules are imported here, make sure everything is installed by running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from random import randint\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "from typing import Dict\n",
    "\n",
    "import tenseal as ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TenSEAL Context\n",
    "\n",
    "TenSEAL context is the central component of the library.  It stores the keys and states required by an encrypted computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context():\n",
    "    context = ts.context(ts.SCHEME_TYPE.CKKS, 8192, coeff_mod_bit_sizes=[60, 40, 40, 60])\n",
    "    context.global_scale = pow(2, 40)\n",
    "    context.generate_galois_keys()\n",
    "    return context\n",
    "\n",
    "context = context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plain tensor creation\n",
    "\n",
    "PlainTensor class works as a translation layer from common tensor representations to the encrypted forms offered by TenSEAL.\n",
    "\n",
    "<img src=\"assets/plaintensor_indepth.png\" align=\"center\" style=\"display: block;  margin: auto;\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " First tensor: Shape = [2, 2] Data = [[1.0, 2.0], [3.0, 4.0]]\n",
      " Second tensor: Shape = [2, 2] Data = [[5.0, 6.0], [7.0, 8.0]]\n"
     ]
    }
   ],
   "source": [
    "plain1 = ts.plain_tensor([1,2,3,4], [2,2])\n",
    "plain1_list = ts.tolist(plain1)\n",
    "print(\" First tensor: Shape = {} Data = {}\".format(plain1.shape(), plain1_list))\n",
    "\n",
    "plain2 = ts.plain_tensor(np.array([5,6,7,8]).reshape(2,2))\n",
    "plain2_list = ts.tolist(plain2)\n",
    "print(\" Second tensor: Shape = {} Data = {}\".format(plain2.shape(), plain2_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encrypted tensor creation\n",
    "\n",
    "The encrypted tensor encrypts a PlainTensor and stores the ciphertexts and shapes internally.\n",
    "\n",
    "We have a few variants of encrypted tensors:\n",
    " - **BFVVector** - for 1d integer arrays.\n",
    " - **CKKSVector** - for 1d float arrays.\n",
    " - **CKKSTensor** - for n-dimensional float arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape = [2, 2]\n",
      " Encrypted Data = [<_tenseal_cpp.Ciphertext object at 0x7f85481ebeb0>, <_tenseal_cpp.Ciphertext object at 0x7f85481ebd30>, <_tenseal_cpp.Ciphertext object at 0x7f85481eb7b0>, <_tenseal_cpp.Ciphertext object at 0x7f85481ebef0>].\n"
     ]
    }
   ],
   "source": [
    "encrypted_tensor1 = ts.ckks_tensor(context, plain1)\n",
    "encrypted_tensor2 = ts.ckks_tensor(context, plain2)\n",
    "\n",
    "print(\" Shape = {}\".format(encrypted_tensor1.shape()))\n",
    "print(\" Encrypted Data = {}.\".format(encrypted_tensor1.data()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrypt(enc):\n",
    "    return ts.tolist(enc.decrypt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 2.0], [3.0, 4.0]] + [[5.0, 6.0], [7.0, 8.0]]\n",
      "Result = [[6.0000000000934275, 8.000000000598334], [9.999999999436515, 11.999999999901778]].\n"
     ]
    }
   ],
   "source": [
    "result = encrypted_tensor1 + encrypted_tensor2\n",
    "print(\"{} + {}\\nResult = {}.\".format(plain1_list, plain2_list, decrypt(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 2.0], [3.0, 4.0]] - [[5.0, 6.0], [7.0, 8.0]] = [[-3.9999999999774807, -4.000000000359499], [-3.9999999997401745, -3.999999999676751]].\n"
     ]
    }
   ],
   "source": [
    "result = encrypted_tensor1 - encrypted_tensor2\n",
    "print(\"{} - {} = {}.\".format(plain1_list, plain2_list, decrypt(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiplication: [[1.0, 2.0], [3.0, 4.0]] * [[5.0, 6.0], [7.0, 8.0]] = [[5.000000670637614, 12.000001611136117], [21.000002814176568, 32.00000429151612]].\n"
     ]
    }
   ],
   "source": [
    "result = encrypted_tensor1 * encrypted_tensor2\n",
    "print(\"Multiplication: {} * {} = {}.\".format(plain1_list, plain2_list, decrypt(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplication with plain tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 2.0], [3.0, 4.0]] * [[5.0, 6.0], [7.0, 8.0]] = [[5.0000006706086015, 12.000001610050523], [21.00000281530351, 32.00000429223313]].\n"
     ]
    }
   ],
   "source": [
    "plain = ts.plain_tensor([5,6,7,8], [2,2])\n",
    "result = encrypted_tensor1 * plain\n",
    "\n",
    "print(\"{} * {} = {}.\".format(plain1_list, ts.tolist(plain), decrypt(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 2.0], [3.0, 4.0]] ^ 3 = [[1.0000008044146802, 8.00000643879611], [27.000021722079637, 64.00005150404499]].\n"
     ]
    }
   ],
   "source": [
    "result = encrypted_tensor1 ** 3\n",
    "print(\"{} ^ 3 = {}.\".format(plain1_list, decrypt(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial evaluation $1 + X^2 + X^3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [[1.0, 2.0], [3.0, 4.0]]\n",
      "1 + X^2 + X^3 = [[3.0000009387224145, 13.00000697594077], [37.000022928156724, 81.00005365071301]].\n"
     ]
    }
   ],
   "source": [
    "result = encrypted_tensor1.polyval([1,0,1,1])\n",
    "\n",
    "print(\"X = {}\".format(plain1_list))\n",
    "print(\"1 + X^2 + X^3 = {}.\".format(decrypt(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid approximation\n",
    "$\\sigma(x) = 0.5 + 0.197 x - 0.004 x^3$\n",
    "\n",
    "Reference: [\"Logistic regression over encrypted data from fully homomorphic encryption\", Hao Chen et al](https://eprint.iacr.org/2018/462.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [[1.0, 2.0], [3.0, 4.0]]\n",
      "0.5 + 0.197 X - 0.004 x^X = [[0.693000022855601, 0.8620000226215272], [0.9829999772307648, 1.0319998694184693]].\n"
     ]
    }
   ],
   "source": [
    "result = encrypted_tensor1.polyval([0.5, 0.197, 0, -0.004])\n",
    "\n",
    "\n",
    "print(\"X = {}\".format(plain1_list))\n",
    "print(\"0.5 + 0.197 X - 0.004 x^X = {}.\".format(decrypt(result)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encrypted inference demo\n",
    "\n",
    "The next example contains a classification over the MNIST dataset using a single convolution and two fully connected layer with a square activation function.\n",
    "\n",
    "\n",
    "\n",
    "Adapted from https://github.com/youben11/encrypted-evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the TenSEAL security context\n",
    "def create_ctx():\n",
    "    poly_mod_degree = 8192\n",
    "    coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
    "    ctx = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "    ctx.global_scale = 2 ** 21\n",
    "    ctx.generate_galois_keys()\n",
    "    return ctx\n",
    "\n",
    "# Sample an image\n",
    "def load_input():\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    )\n",
    "    idx = randint(1, 39)\n",
    "    img_name = \"samples/img_{}.jpg\".format(idx)\n",
    "    img = Image.open(img_name)\n",
    "    return transform(img).view(28, 28).tolist(), img\n",
    "\n",
    "# Encode the image\n",
    "def prepare_input(ctx, plain_input):\n",
    "    enc_input, windows_nb = ts.im2col_encoding(ctx, plain_input, 7, 7, 3)\n",
    "    assert windows_nb == 64\n",
    "    return enc_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server Model\n",
    "\n",
    " - We have a pretrained plain model.\n",
    " - We adapt the forward call for encrypted inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model and adapt the forward call for encrypted input\n",
    "class ConvMNIST():\n",
    "    \"\"\"CNN for classifying MNIST data.\n",
    "    Input should be an encoded 28x28 matrix representing the image.\n",
    "    TenSEAL can be used for encoding `tenseal.im2col_encoding(ctx, input_matrix, 7, 7, 3)`\n",
    "    The input should also be normalized with a mean=0.1307 and an std=0.3081 before encryption.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, parameters: Dict[str, list]):\n",
    "        self.conv1_weight = parameters[\"conv1_weight\"]\n",
    "        self.conv1_bias = parameters[\"conv1_bias\"]\n",
    "        self.fc1_weight = parameters[\"fc1_weight\"]\n",
    "        self.fc1_bias = parameters[\"fc1_bias\"]\n",
    "        self.fc2_weight = parameters[\"fc2_weight\"]\n",
    "        self.fc2_bias = parameters[\"fc2_bias\"]\n",
    "        self.windows_nb = parameters[\"windows_nb\"]\n",
    "\n",
    "    def forward(self, enc_x: ts.CKKSVector) -> ts.CKKSVector:\n",
    "        # conv layer\n",
    "        channels = []\n",
    "        for kernel, bias in zip(self.conv1_weight, self.conv1_bias):\n",
    "            y = enc_x.conv2d_im2col(kernel, self.windows_nb) + bias\n",
    "            channels.append(y)\n",
    "        out = ts.CKKSVector.pack_vectors(channels)\n",
    "        # squaring\n",
    "        out.square_()\n",
    "        # no need to flat\n",
    "        # fc1 layer\n",
    "        out.mm_(self.fc1_weight).add_plain_(self.fc1_bias)\n",
    "        # squaring\n",
    "        out.square_()\n",
    "        # output layer\n",
    "        out.mm_(self.fc2_weight).add_plain_(self.fc2_bias)\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_input(context: bytes, ckks_vector: bytes) -> ts.CKKSVector:\n",
    "        try:\n",
    "            ctx = ts.context_from(context)\n",
    "            enc_x = ts.ckks_vector_from(ctx, ckks_vector)\n",
    "        except:\n",
    "            raise DeserializationError(\"cannot deserialize context or ckks_vector\")\n",
    "        try:\n",
    "            _ = ctx.galois_keys()\n",
    "        except:\n",
    "            raise InvalidContext(\"the context doesn't hold galois keys\")\n",
    "\n",
    "        return enc_x\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from 'parameters/ConvMNIST-0.1.pickle'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "def load_parameters(file_path: str) -> dict:\n",
    "    try:\n",
    "        parameters = pickle.load(open(file_path, \"rb\"))\n",
    "        print(f\"Model loaded from '{file_path}'\")\n",
    "    except OSError as ose:\n",
    "        print(\"error\", ose)\n",
    "        raise ose\n",
    "    return parameters\n",
    "\n",
    "\n",
    "\n",
    "parameters = load_parameters(\"parameters/ConvMNIST-0.1.pickle\")\n",
    "model = ConvMNIST(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Query\n",
    "\n",
    "**Steps**:\n",
    " - Context creation(only for the first query).\n",
    " - Image sampling and encryption.\n",
    " - Image and context serialization using **Protobuffers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encrypted image  <_tenseal_cpp.CKKSVector object at 0x7f85440f09f0>\n",
      "Original image \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "context = create_ctx()\n",
    "image, orig = load_input()\n",
    "    \n",
    "encrypted_image = prepare_input(context, image)\n",
    "\n",
    "print(\"Encrypted image \", encrypted_image)\n",
    "print(\"Original image \")\n",
    "imshow(np.asarray(orig))\n",
    "\n",
    "server_context = context.serialize()\n",
    "encrypted_image = encrypted_image.serialize()\n",
    "\n",
    "\n",
    "\n",
    "client_query = {\n",
    "    \"data\" : encrypted_image,\n",
    "    \"context\" : server_context,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server inference\n",
    "\n",
    "**Steps**:\n",
    " - Deserialize the context and the encrypted image.\n",
    " - Run the inference.\n",
    " - Serialize and return the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encrypted_query = model.prepare_input(client_query[\"context\"], client_query[\"data\"])\n",
    "encrypted_result = model(encrypted_query).serialize()\n",
    "\n",
    "server_response = {\n",
    "    \"data\" : encrypted_result\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client process response\n",
    "\n",
    "Steps:\n",
    " - Deserialize the response.\n",
    " - Decrypt the response.\n",
    " - Apply a softmax and return the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum probability for label 9\n"
     ]
    }
   ],
   "source": [
    "result = ts.ckks_vector_from(context, server_response[\"data\"]).decrypt()\n",
    "\n",
    "probs = torch.softmax(torch.tensor(result), 0)\n",
    "label_max = torch.argmax(probs)\n",
    "print(\"Maximum probability for label {}\".format(label_max))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
