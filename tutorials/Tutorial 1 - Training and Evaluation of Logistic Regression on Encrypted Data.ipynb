{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Training and Evaluation of Logistic Regression on Encrypted Data\n",
    "\n",
    "Welcome to this first use case tutorial, where we are going to show how to use TenSEAL for training and evaluating a logistic regression (LR) model on encrypted data (using homomorphic encryption) for heart disease prediction! If you haven't played with TenSEAL before, or need a quick overview of what homomorphic encryption is, I would suggest going through ['Tutorial 0 - Getting Started'](./Tutorial%200%20-%20Getting%20Started.ipynb) first.\n",
    "\n",
    "\n",
    "**Disclaimer:** The goal of this tutorial isn't to show how efficient logistic regression is for this task, we will just go with whatever accuracy we get, but the training and evaluation on encrypted data should be comparable to when we use plain data.\n",
    "\n",
    "\n",
    "Authors:\n",
    "- Ayoub Benaissa - Twitter: [@y0uben11](https://twitter.com/y0uben11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "All modules are imported here, make sure everything is installed by running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tenseal as ts\n",
    "import pandas as pd\n",
    "import random\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now prepare the training and test data, the dataset was downloaded from Kaggle [here](https://www.kaggle.com/dileep070/heart-disease-prediction-using-logistic-regression), this dataset provides patients' information along with a 10-year risk of future coronary heart disease (CHD) as a label, and the goal is to build a model that can predict this 10-year CHD risk from patients' information, you can read more about the dataset in the link provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train has shape: torch.Size([1024, 2])\n",
      "y_train has shape: torch.Size([1024, 1])\n",
      "x_test has shape: torch.Size([1024, 2])\n",
      "y_test has shape: torch.Size([1024, 1])\n"
     ]
    }
   ],
   "source": [
    "torch.random.manual_seed(73)\n",
    "random.seed(73)\n",
    "\n",
    "\n",
    "def random_data(m=1024, n=2):\n",
    "    x_train = torch.randn(m, n)\n",
    "    x_test = torch.randn(m, n)\n",
    "    y_train = (x_train[:, 0] >= x_train[:, 1]).float().unsqueeze(0).t()\n",
    "    y_test = (x_test[:, 0] >= x_test[:, 1]).float().unsqueeze(0).t()\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def split_train_test(x, y, test_ratio=0.3):\n",
    "    assert len(x) == len(y)\n",
    "    idxs = list(range(len(x)))\n",
    "    random.shuffle(idxs)\n",
    "    delim = int(len(x) * test_ratio)\n",
    "    test_idxs, train_idxs = idxs[:delim], idxs[delim:]\n",
    "    return x[train_idxs], y[train_idxs], x[test_idxs], y[test_idxs]\n",
    "\n",
    "\n",
    "def heart_disease_data():\n",
    "    data = pd.read_csv(\"./data/framingham.csv\")\n",
    "    # drop rows with missing values\n",
    "    data = data.dropna()\n",
    "    y = torch.tensor(data[\"TenYearCHD\"].values).float().unsqueeze(1)\n",
    "    # drop label column\n",
    "    data = data.drop(\"TenYearCHD\", 'columns')\n",
    "    # normalize\n",
    "    data = (data - data.mean()) / data.std()\n",
    "    x = torch.tensor(data.values).float()\n",
    "    return split_train_test(x, y)\n",
    "\n",
    "\n",
    "x_train, y_train, x_test, y_test = random_data()\n",
    "# x_train, y_train, x_test, y_test = heart_disease_data()\n",
    "print(f\"x_train has shape: {x_train.shape}\")\n",
    "print(f\"y_train has shape: {y_train.shape}\")\n",
    "print(f\"x_test has shape: {x_test.shape}\")\n",
    "print(f\"y_test has shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Logistic Regression Model\n",
    "\n",
    "We are going to use a LR model, which can be viewed as a single layer neural network with a single node. Let's use PyTorch for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_features):\n",
    "        super(LR, self).__init__()\n",
    "        self.lr = torch.nn.Linear(n_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.sigmoid(self.lr(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = x_train.shape[1]\n",
    "model = LR(n_features)\n",
    "# use gradient descent with a learning_rate=1\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1)\n",
    "# use Binary Cross Entropy Loss\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1: 1.1047818660736084\n",
      "Loss at epoch 2: 0.7850252985954285\n",
      "Loss at epoch 3: 0.5968001484870911\n",
      "Loss at epoch 4: 0.49308696389198303\n",
      "Loss at epoch 5: 0.43031832575798035\n",
      "Loss at epoch 6: 0.3880561590194702\n",
      "Loss at epoch 7: 0.35731425881385803\n",
      "Loss at epoch 8: 0.3337048292160034\n",
      "Loss at epoch 9: 0.3148457407951355\n",
      "Loss at epoch 10: 0.2993296682834625\n"
     ]
    }
   ],
   "source": [
    "def train(model, optim, criterion, x, y, epochs=10):\n",
    "    for e in range(1, epochs + 1):\n",
    "        optim.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        print(f\"Loss at epoch {e}: {loss.data}\")\n",
    "    return model\n",
    "\n",
    "model = train(model, optim, criterion, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on plain test_set: 0.9873046875\n"
     ]
    }
   ],
   "source": [
    "def accuracy(model, x, y):\n",
    "    out = model(x)\n",
    "    correct = torch.abs(y - out) < 0.5\n",
    "    return correct.float().mean()\n",
    "\n",
    "plain_accuracy = accuracy(model, x_test, y_test)\n",
    "print(f\"Accuracy on plain test_set: {plain_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encrypted Evaluation\n",
    "\n",
    "In this part, we will just focus on evaluating the logistic regression model with plain parameters (optionally encrypted parameters) on the encrypted test-set. We first create a PyTorch-like LR model that can evaluate encrypted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncryptedLR:\n",
    "    \n",
    "    def __init__(self, torch_lr):\n",
    "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
    "        self.bias = torch_lr.lr.bias.data.tolist()\n",
    "        \n",
    "    def forward(self, enc_x):\n",
    "        enc_out = enc_x.dot(self.weight) + self.bias\n",
    "        return enc_out\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "        \n",
    "    ################################################\n",
    "    ## You can use the functions below to perform ##\n",
    "    ## the evaluation with an encrypted model     ##\n",
    "    ################################################\n",
    "    \n",
    "    def encrypt(self, context):\n",
    "        self.weight = ts.ckks_vector(context, self.weight)\n",
    "        self.bias = ts.ckks_vector(context, self.bias)\n",
    "        \n",
    "    def decrypt(self, context):\n",
    "        self.weight = self.weight.decrypt()\n",
    "        self.bias = self.bias.decrypt()\n",
    "        \n",
    "\n",
    "eelr = EncryptedLR(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a TenSEALContext for specifying the scheme and the parameters we are going to use. Here we choose small and secure parameteres that allows us to make a single multiplication, that's enough for evaluating a LR model, however, we will see that we need larger parameters when doing training on encrypted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_eval = ts.context(ts.SCHEME_TYPE.CKKS, 4096, 0, [40, 20, 40])\n",
    "# scale of ciphertext to use\n",
    "ctx_eval.global_scale = 2 ** 20\n",
    "# this key is needed for doing dot-product operations\n",
    "ctx_eval.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will encrypt the whole test-set before the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the test_set took 4 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_x_test = [ts.ckks_vector(ctx_eval, x.tolist()) for x in x_test]\n",
    "t_end = time()\n",
    "print(f\"Encryption of the test_set took {int(t_end - t_start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) encrypt the model's parameters\n",
    "# eelr.encrypt(ctx_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have already noticed when we built the EncryptedLR class, we doesn't compute the sigmoid function on the encrypted output of the linear layer, simply because it's not needed, and computing sigmoid over encrypted data will increase the computation time and need larger encryption parameters. In a client server scenario, the client would encrypt the data and send it for evaluation to the server, the server can just send the evaluation of the linear layer, the client would then decrypt the result and can guess the label by tranforming the output into a probability using sigmoid, or just by comparing if it's greater or less than zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated test_set of 1024 entries in 3 seconds\n",
      "Accuracy: 1014/1024 = 0.990234375\n",
      "Difference between plain and encrypted accuracies: -0.0029296875\n"
     ]
    }
   ],
   "source": [
    "def encrypted_evaluation(model, enc_x_test, y_test):\n",
    "    t_start = time()\n",
    "    \n",
    "    correct = 0\n",
    "    for enc_x, y in zip(enc_x_test, y_test):\n",
    "        # encrypted evaluation\n",
    "        enc_out = model(enc_x)\n",
    "        # plain comparaison\n",
    "        out = enc_out.decrypt()\n",
    "        out = torch.tensor(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        if torch.abs(out - y) < 0.5:\n",
    "            correct += 1\n",
    "    \n",
    "    t_end = time()\n",
    "    print(f\"Evaluated test_set of {len(x_test)} entries in {int(t_end - t_start)} seconds\")\n",
    "    print(f\"Accuracy: {correct}/{len(x_test)} = {correct / len(x_test)}\")\n",
    "    return correct / len(x_test)\n",
    "    \n",
    "\n",
    "encrypted_accuracy = encrypted_evaluation(eelr, enc_x_test, y_test)\n",
    "print(f\"Difference between plain and encrypted accuracies: {plain_accuracy - encrypted_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that evaluating on the encrypted test-set doesn't affect that much the accuracy, I've even seen examples where the encrypted evaluation performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an Encrypted Logistic Regression Model on Encrypted Data\n",
    "\n",
    "In this part we will redifine a PyTorch-like model than can both forward encrypted data, as well backprobagate to update the weights and thus train the encrypted LR model on encrypted data.\n",
    "\n",
    "Explains mathematically the operations and why we need a certain depth:\n",
    "- which loss are we using?\n",
    "- why did we choose a learning rate of 1?\n",
    "- the update formula\n",
    "- output range to see if the sigmoid approximation fits\n",
    "\n",
    "To experiment:\n",
    "- study the function approximation vs linear layer output distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncryptedLR:\n",
    "    \n",
    "    def __init__(self, torch_lr):\n",
    "        self.weight = torch_lr.lr.weight.data.tolist()[0]\n",
    "        self.bias = torch_lr.lr.bias.data.tolist()\n",
    "        self._delta_w = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "        \n",
    "    def forward(self, enc_x):\n",
    "        enc_out = enc_x.dot(self.weight) + self.bias\n",
    "        enc_out = EncryptedLR.sigmoid(enc_out)\n",
    "        return enc_out\n",
    "    \n",
    "    def backward(self, enc_x, enc_out, enc_y):\n",
    "        # TODO: right operations\n",
    "        out_minus_y = (enc_out - enc_y)\n",
    "        #self._delta_w += enc_x * out_minus_y\n",
    "        #self._delta_b += out_minus_y\n",
    "        self._delta_w = enc_x * out_minus_y + self._delta_w\n",
    "        self._delta_b = out_minus_y + self._delta_b\n",
    "        self._count += 1\n",
    "        \n",
    "    def update_parameters(self):\n",
    "        # update weights\n",
    "        self.weight -= self._delta_w * (1 / self._count) + self.weight * 0.2\n",
    "        self.bias -= self._delta_b * (1 / self._count)\n",
    "        # reset\n",
    "        self._delta_w = 0\n",
    "        self._delta_b = 0\n",
    "        self._count = 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(enc_x):\n",
    "        # https://eprint.iacr.org/2018/462.pdf\n",
    "        # look into https://eprint.iacr.org/2018/254.pdf\n",
    "        third_term = (enc_x * enc_x) * (enc_x * -0.004)\n",
    "        return third_term + enc_x * 0.197 + 0.5\n",
    "    \n",
    "    def plain_accuracy(self, x_test, y_test):\n",
    "        w = torch.tensor(self.weight)\n",
    "        b = torch.tensor(self.bias)\n",
    "        out = torch.sigmoid(x_test.matmul(w) + b).reshape(-1, 1)\n",
    "        correct = torch.abs(y_test - out) < 0.5\n",
    "        return correct.float().mean()    \n",
    "    \n",
    "    def encrypt(self, context):\n",
    "        self.weight = ts.ckks_vector(context, self.weight)\n",
    "        self.bias = ts.ckks_vector(context, self.bias)\n",
    "        \n",
    "    def decrypt(self):\n",
    "        self.weight = self.weight.decrypt()\n",
    "        self.bias = self.bias.decrypt()\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Parameters (128-bit security) ##########\n",
    "# poly_mod_degree 8192 -> total bit count 218 \n",
    "# poly_mod_degree 16384 -> total bit count 438\n",
    "# poly_mod_degree 32768 -> total bit count 881\n",
    "################################################\n",
    "\n",
    "a, b = 40, 21\n",
    "coeff_bit_size = [a] + [b] * 6 + [a]\n",
    "ctx_training = ts.context(ts.SCHEME_TYPE.CKKS, 8192, -1, coeff_bit_size)\n",
    "ctx_training.global_scale = 2 ** b\n",
    "ctx_training.generate_galois_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encryption of the training_set took 36 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time()\n",
    "enc_x_train = [ts.ckks_vector(ctx_training, x.tolist()) for x in x_train]\n",
    "enc_y_train = [ts.ckks_vector(ctx_training, y.tolist()) for y in y_train]\n",
    "t_end = time()\n",
    "print(f\"Encryption of the training_set took {int(t_end - t_start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# study linear layer output distribution\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "normal_dist = lambda x, mean, var: np.exp(- np.square(x - mean) / (2 * var)) / np.sqrt(2 * np.pi * var)\n",
    "\n",
    "def plot_normal_dist(mean, var, rmin=-10, rmax=10):\n",
    "    x = np.arange(rmin, rmax, 0.01)\n",
    "    y = normal_dist(x, mean, var)\n",
    "    plt.plot(x, y)\n",
    "    \n",
    "# plain distribution\n",
    "lr = LR(n_features)\n",
    "data = lr.lr(x_test)\n",
    "mean, var = map(float, [data.mean(), data.std() ** 2])\n",
    "plot_normal_dist(mean, var)\n",
    "plt.show()\n",
    "\n",
    "# encrypted distribution\n",
    "def encrypted_out_distribution(eelr, enc_x_test):\n",
    "    w = eelr.weight\n",
    "    b = eelr.bias\n",
    "    data = []\n",
    "    for enc_x in enc_x_test:\n",
    "        enc_out = enc_x.dot(w) + b\n",
    "        data.append(enc_out.decrypt())\n",
    "    data = torch.tensor(data)\n",
    "    mean, var = map(float, [data.mean(), data.std() ** 2])\n",
    "    plot_normal_dist(mean, var)\n",
    "    plt.show()\n",
    "\n",
    "eelr = EncryptedLR(lr)\n",
    "eelr.encrypt(ctx_training)\n",
    "encrypted_out_distribution(eelr, enc_x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encrypted Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before starting the training is 0.3505859375\n",
      "Accuracy at epoch #1 is 0.9150390625\n",
      "weight [1.036789224653575, -1.1191651715912752]\n",
      "bias [0.34182853180075135]\n",
      "#################################################\n",
      "Accuracy at epoch #2 is 0.9287109375\n",
      "weight [1.049571015653144, -1.1129154766007665]\n",
      "bias [0.28674852486275193]\n",
      "#################################################\n",
      "Accuracy at epoch #3 is 0.9375\n",
      "weight [1.049932452552298, -1.109997748854132]\n",
      "bias [0.24328651016507638]\n",
      "#################################################\n",
      "Accuracy at epoch #4 is 0.947265625\n",
      "weight [1.0485061673133294, -1.1045640773950407]\n",
      "bias [0.20905391292616435]\n",
      "#################################################\n",
      "Accuracy at epoch #5 is 0.9560546875\n",
      "weight [1.0458910388662745, -1.0994145636204251]\n",
      "bias [0.18220053015799687]\n",
      "#################################################\n",
      "Accuracy at epoch #6 is 0.958984375\n",
      "weight [1.0422166205665264, -1.0939246582705708]\n",
      "bias [0.1604971822285567]\n",
      "#################################################\n",
      "Accuracy at epoch #7 is 0.9619140625\n",
      "weight [1.039287063118906, -1.089326731691335]\n",
      "bias [0.14375978902165104]\n",
      "#################################################\n",
      "Accuracy at epoch #8 is 0.966796875\n",
      "weight [1.0376553310628236, -1.085488780277257]\n",
      "bias [0.13057838197882765]\n",
      "#################################################\n",
      "Accuracy at epoch #9 is 0.96875\n",
      "weight [1.0355554249135392, -1.085049990453475]\n",
      "bias [0.12009845420650875]\n",
      "#################################################\n",
      "Accuracy at epoch #10 is 0.970703125\n",
      "weight [1.0345485206443423, -1.0826360824333499]\n",
      "bias [0.1114841302834637]\n",
      "#################################################\n",
      "\n",
      "Average time per epoch: 126 seconds\n"
     ]
    }
   ],
   "source": [
    "eelr = EncryptedLR(LR(n_features))\n",
    "accuracy = eelr.plain_accuracy(x_test, y_test)\n",
    "print(f\"Accuracy at epoch #0 is {accuracy}\")\n",
    "\n",
    "epochs = 10\n",
    "times = []\n",
    "for epoch in range(epochs):\n",
    "    eelr.encrypt(ctx_training)\n",
    "    \n",
    "    # if you want to keep an eye on the distribution\n",
    "    #encrypted_out_distribution(eelr, enc_x_train)\n",
    "    \n",
    "    t_start = time()\n",
    "    for enc_x, enc_y in zip(enc_x_train, enc_y_train):\n",
    "        enc_out = eelr.forward(enc_x)\n",
    "        eelr.backward(enc_x, enc_out, enc_y)\n",
    "    eelr.update_parameters()\n",
    "    t_end = time()\n",
    "    times.append(t_end - t_start)\n",
    "    \n",
    "    eelr.decrypt()\n",
    "    accuracy = eelr.plain_accuracy(x_test, y_test)\n",
    "    print(f\"Accuracy at epoch #{epoch + 1} is {accuracy}\")\n",
    "    print(\"weight\", eelr.weight)\n",
    "    print(\"bias\", eelr.bias)\n",
    "    print(\"#################################################\")\n",
    "\n",
    "\n",
    "print(f\"\\nAverage time per epoch: {int(sum(times) / epochs)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!!! - Time to Join the Community!\n",
    "\n",
    "Congratulations on completing this notebook tutorial! If you enjoyed this and would like to join the movement toward privacy preserving, decentralized ownership of AI and the AI supply chain (data), you can do so in the following ways!\n",
    "\n",
    "### Star TenSEAL on GitHub\n",
    "\n",
    "The easiest way to help our community is just by starring the Repos! This helps raise awareness of the cool tools we're building.\n",
    "\n",
    "- [Star TenSEAL](https://github.com/OpenMined/TenSEAL)\n",
    "\n",
    "### Join our Slack!\n",
    "\n",
    "The best way to keep up to date on the latest advancements is to join our community! You can do so by filling out the form at [http://slack.openmined.org](http://slack.openmined.org). #lib_tenseal and #code_tenseal are the main channels for the TenSEAL project.\n",
    "\n",
    "### Join our Team!\n",
    "\n",
    "If you're excited about what we are working on TenSEAL, and if you're interested to work on homomorphic encryption related use cases, you should definitely join us!\n",
    "\n",
    "[Apply to the crypto team!](https://docs.google.com/forms/d/1T6MJ21V1lb7aEr4ilZOTYQXzxXP6KbpLumZVmTZMSuY/edit)\n",
    "\n",
    "\n",
    "### Donate\n",
    "\n",
    "If you don't have time to contribute to our codebase, but would still like to lend support, you can also become a Backer on our Open Collective. All donations go toward our web hosting and other community expenses such as hackathons and meetups!\n",
    "\n",
    "[OpenMined's Open Collective Page](https://opencollective.com/openmined)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
